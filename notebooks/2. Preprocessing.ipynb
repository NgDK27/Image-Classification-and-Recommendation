{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7356d0bb0c37110e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3a56b58498b093",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---\n",
    "## Imports"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.augmentation import augment_image\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.duplicates import remove_rows, get_duplicates_to_delete"
   ],
   "id": "ddb0fa2d64e88264"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.read_csv('../data/processed/csv/df.csv')\n",
    "duplicates = pd.read_csv('../data/processed/csv/duplicates.csv')"
   ],
   "id": "862fc09f0edc545b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "--- \n",
    "## Remove duplicates"
   ],
   "id": "8b8cd9d7ffc9684c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Automatically delete:\n",
    "- For each duplicate group, delete all but one rows marked as \"Duplicate\" for each \"Style\".\n",
    "- Outputs \"df_no_dup\"."
   ],
   "id": "b2c31c0220982e8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "duplicates_to_delete = get_duplicates_to_delete(duplicates)\n",
    "df_no_dup = remove_rows(df, duplicates_to_delete)\n",
    "df_no_dup"
   ],
   "id": "40efac2f1d0da969"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Manually delete:\n",
    "- Any rows marked as \"Inspect\" that belongs in the wrong \"Class\".\n",
    "- Overwrite \"df\", as this DataFrame will continue to be used for further preprocessing."
   ],
   "id": "56afab5abc5ec9cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "inspects = duplicates[duplicates['Duplicate_Type'] == 'Inspect']\n",
    "inspects"
   ],
   "id": "a28ce6a7125346b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "total_inspect_groups = inspects[\"Group\"].nunique(dropna=False)",
   "id": "3265b174cfa950f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# inspects_rows_to_delete = [91, 154, 205, 227, 235, 277, 280, 281, 287, 290, 299, 310, 318, 323, 325] # Delete one of each pair\n",
    "inspects_rows_to_delete = [91,\n",
    "                           205]  # Only delete very different class (\"tables\" and \"beds\"). Similar classes are kept (\"chairs\" and \"sofas\")"
   ],
   "id": "e8bd96f6dd721901"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "inspect_review = inspects.copy()\n",
    "inspect_review[\"Duplicate_Type\"] = \"Keep\"\n",
    "# inspect_review.loc[inspects_rows_to_delete, \"Duplicate_Type\"] = \"DELETE\""
   ],
   "id": "aa9c757e7f364a51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# visualize_duplicates(inspect_review, total_inspect_groups)",
   "id": "8cceb7db70734f8d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "inspects_to_delete = inspect_review[inspect_review[\"Duplicate_Type\"] == \"DELETE\"]\n",
    "inspects_to_delete"
   ],
   "id": "3a7093ab636c6b7f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = remove_rows(df, inspects_to_delete)\n",
    "df"
   ],
   "id": "8087cf777d0695cd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Prepare DataFrame"
   ],
   "id": "4133b8ff325ed067"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have the original \"df\" and \"duplicates_to_delete\" DataFrames\n",
    "\n",
    "# Merge the two DataFrames based on the \"Path\" column\n",
    "merged_df = pd.merge(df, duplicates_to_delete[['Path']], on='Path', how='left', indicator=True)\n",
    "\n",
    "# Create the \"Duplicate_Type\" column based on the merge indicator\n",
    "merged_df['Duplicate_Type'] = merged_df['_merge'].map({'both': \"Duplicate\", 'left_only': \"Unique\"})\n",
    "\n",
    "# Drop the merge indicator column\n",
    "merged_df = merged_df.drop('_merge', axis=1)\n",
    "\n",
    "# Update the original \"df\" with the new \"Duplicate_Type\" column\n",
    "df = merged_df"
   ],
   "id": "2ca0842e813b6741"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df",
   "id": "36f18ed6ab718576"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Split (train, validation, test)"
   ],
   "id": "9ab2a7eba889edc6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prepare target and training",
   "id": "c5d0863b8fb7fbe9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_data = df.copy()",
   "id": "a60520e97196c2a8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Splitting",
   "id": "cb40b1c50339a730"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_X, test_X = train_test_split(\n",
    "    train_data,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "train_X, val_X = train_test_split(\n",
    "    train_X,\n",
    "    test_size=0.25,\n",
    "    random_state=42\n",
    ")"
   ],
   "id": "5b910219738dd67e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_X",
   "id": "bfd8c472b51684c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Rescaling & Normalization\n",
    "Note: Using Tensorflow for quick normalization and rescaling. In 'utils/tensorflow_preprocessing.py' file, there is a functions to normalize and rescale the each image in the dataset."
   ],
   "id": "51e886a28670b292"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ],
   "id": "f1cda72d2ad1037e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def process_image_from_path(image_path, img_height, img_width, to_augment):\n",
    "    # Read image\n",
    "    img = tf.io.read_file(image_path)\n",
    "\n",
    "    # Decode to RGB\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "\n",
    "    # Resize\n",
    "    img = tf.image.resize(img, [img_height, img_width])\n",
    "\n",
    "    # Augment\n",
    "    is_duplicate = tf.equal(to_augment, \"Duplicate\")\n",
    "    img = tf.cond(is_duplicate, lambda: augment_image(img), lambda: img)\n",
    "\n",
    "    # Rescale\n",
    "    rescaling_layer = tf.keras.layers.Rescaling(scale=1. / 255)\n",
    "    img = rescaling_layer(img) \n",
    "    # Commented out right now cause it makes all the output image black, which I'm not sure is supposed to happen\n",
    "\n",
    "    return img"
   ],
   "id": "430ea3863c3820f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def prepare_image_dataset(df, img_height, img_width, batch_size, base_path='../data/raw/Furniture_Data',\n",
    "                          label_encoder=None):\n",
    "    prepared_df = df.assign(Path=df['Path'].apply(lambda path: base_path + \"/\" + path))\n",
    "\n",
    "    # REMOVE (shorten the df for faster testing)\n",
    "    # prepared_df = prepared_df.sample(frac=0.05, random_state=42)\n",
    "\n",
    "    # Perform label encoding on the class labels\n",
    "    if label_encoder is None:\n",
    "        label_encoder = LabelEncoder()\n",
    "        prepared_df['Class_Encoded'] = label_encoder.fit_transform(prepared_df['Class'])\n",
    "    else:\n",
    "        prepared_df['Class_Encoded'] = label_encoder.transform(prepared_df['Class'])\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (prepared_df['Path'].values,\n",
    "         prepared_df[\"Duplicate_Type\"].values,\n",
    "         prepared_df['Class_Encoded'].values)\n",
    "    )\n",
    "\n",
    "    image_ds = dataset.map(lambda path, duplicate_type, class_label:\n",
    "                           (\n",
    "                               process_image_from_path(image_path=path,\n",
    "                                                       img_height=img_height,\n",
    "                                                       img_width=img_width,\n",
    "                                                       to_augment=duplicate_type),\n",
    "                               class_label\n",
    "                           ),\n",
    "                           num_parallel_calls=tf.data.AUTOTUNE\n",
    "                           )\n",
    "\n",
    "    image_ds = image_ds.batch(batch_size)\n",
    "\n",
    "    return image_ds, label_encoder"
   ],
   "id": "b40d8d2d7d4b8f62"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_dataset, label_encoder = prepare_image_dataset(train_X, img_height=256, img_width=256, batch_size=32)\n",
    "val_dataset, _ = prepare_image_dataset(val_X, img_height=256, img_width=256, batch_size=32, label_encoder=label_encoder)\n",
    "test_dataset, _ = prepare_image_dataset(test_X, img_height=256, img_width=256, batch_size=32,\n",
    "                                        label_encoder=label_encoder)"
   ],
   "id": "e861ae3befc44d25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow((images[i]*255).numpy().astype(\"uint8\"))\n",
    "        # plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "# DON'T WORRY if the images here are black. Comment out the rescaling part in process_image_from_path() to see the images."
   ],
   "id": "e6cc04c4835d7269"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Test"
   ],
   "id": "d581e246ab896f3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tensorflow.keras import layers, models, Input\n",
    "from tensorflow.keras.callbacks import ProgbarLogger"
   ],
   "id": "65d03d90266c6010"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = models.Sequential([\n",
    "    Input(shape=(256, 256, 3)),\n",
    "    layers.Conv2D(4, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "    layers.GlobalMaxPooling2D(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5, seed=21),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(1, seed=42),\n",
    "    layers.Dense(128, activation='sigmoid'),\n",
    "    layers.Dense(6, activation='softmax')\n",
    "])"
   ],
   "id": "5b97d16fc2690647"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 3: Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ],
   "id": "591108e97bb5b399"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 4: Train the Model\n",
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=epochs,\n",
    "    batch_size=32,\n",
    "    callbacks=[ProgbarLogger()]\n",
    ")"
   ],
   "id": "d8291e4f37fa9b7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 5: Evaluate the Model\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset, steps=len(test_dataset))\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ],
   "id": "782fc48c9125c598"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(train_dataset.element_spec)",
   "id": "a199c792c543ea4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(test_dataset.element_spec)",
   "id": "d8cafe8f69bd1ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "61879e9556de2461"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
